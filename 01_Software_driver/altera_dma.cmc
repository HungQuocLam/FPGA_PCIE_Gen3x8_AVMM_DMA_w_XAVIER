#include <linux/time.h>
#include <linux/init.h>
#include <linux/fs.h>
#include <linux/module.h>
#include <linux/device.h>
#include <linux/pci.h>
#include <linux/cdev.h>
#include <linux/dma-mapping.h>
#include <linux/interrupt.h>
#include <linux/delay.h>
#include <linux/sched.h>
#include <linux/atomic.h>
#include <linux/random.h>
#include "altera_dma_cmd.h"
#include "altera_dma.h"

static long altera_dma_ioctl (struct file *filp, unsigned int cmd, unsigned long arg)
{
    struct altera_pcie_dma_bookkeep *bk_ptr = filp->private_data;
    switch (cmd) {
        case ALTERA_IOCX_START:
            dma_test(bk_ptr, bk_ptr->pci_dev);
        case ALTERA_CMD_WAIT_DMA: 
            wait_event_interruptible(bk_ptr->wait_q, !atomic_read(&bk_ptr->status));
    }
    return -EINVAL;
}

ssize_t altera_dma_read(struct file *file, char __user *buf, size_t count, loff_t *pos) {
    if (altera_dma_rw(file, buf, count, pos, 1) < 0)
        return -1;
    return count;
}

ssize_t altera_dma_write(struct file *file, char __user *buf, size_t count, loff_t *pos) {
    if (altera_dma_rw(file, buf, count, pos, 0) < 0)
        return -1;
    return count;
}


ssize_t altera_dma_rw(struct file *file, char __user *buf, size_t count, loff_t *pos, int read) {

    struct dma_cmd __user *ucmd_p = (struct dma_cmd *)buf;
    struct altera_pcie_dma_bookkeep *bk_ptr = file->private_data;
    return altera_dma_exec_cmd(ucmd_p, bk_ptr);
}

ssize_t altera_dma_exec_cmd(struct dma_cmd *ucmd, struct altera_pcie_dma_bookkeep * bk_ptr) {
    int rc, num_input;
    struct dma_cmd kcmd;
    struct dma_status curr;
    if (copy_from_user (&kcmd, ucmd, sizeof(struct dma_cmd))) {
        rc = -EFAULT;
        return rc;
    }

    switch (kcmd.cmd) {
        case ALTERA_CMD_ENA_DIS_READ: {
                                          bk_ptr->dma_status.run_read = !bk_ptr->dma_status.run_read;
                                          break;
                                      }
        case ALTERA_CMD_ENA_DIS_WRITE: {
                                           bk_ptr->dma_status.run_write = !bk_ptr->dma_status.run_write;
                                           break;
                                       }
        case ALTERA_CMD_ENA_DIS_SIMUL: {
                                           bk_ptr->dma_status.run_simul = !bk_ptr->dma_status.run_simul;
                                           break;
                                       }
        case ALTERA_CMD_MODIFY_NUM_DWORDS: {
                                               if (copy_from_user (&num_input, kcmd.buf, sizeof(int))) {
                                                   rc = -EFAULT;
                                                   return rc;
                                               }
                                               bk_ptr->dma_status.altera_dma_num_dwords = num_input;
                                               bk_ptr->dma_status.write_time.tv_sec = 0;
                                               bk_ptr->dma_status.read_time.tv_sec = 0;
                                               bk_ptr->dma_status.simul_time.tv_sec = 0;
                                               bk_ptr->dma_status.write_time.tv_usec = 0;
                                               bk_ptr->dma_status.read_time.tv_usec = 0;
                                               bk_ptr->dma_status.simul_time.tv_usec = 0;
                                               break;
                                           }
        case ALTERA_CMD_MODIFY_NUM_DESC: {
                                             if (copy_from_user (&num_input, kcmd.buf, sizeof(int))) {
                                                 rc = -EFAULT;
                                                 return rc;
                                             }
                                             bk_ptr->dma_status.altera_dma_descriptor_num = num_input;
                                             bk_ptr->dma_status.write_time.tv_sec = 0;
                                             bk_ptr->dma_status.read_time.tv_sec = 0;
                                             bk_ptr->dma_status.simul_time.tv_sec = 0;
                                             bk_ptr->dma_status.write_time.tv_usec = 0;
                                             bk_ptr->dma_status.read_time.tv_usec = 0;
                                             bk_ptr->dma_status.simul_time.tv_usec = 0;
                                             break;
                                         }
        case ALTERA_CMD_READ_STATUS: {
                                         bk_ptr->dma_status.length_transfer = (bk_ptr->dma_status.altera_dma_num_dwords*4*bk_ptr->dma_status.altera_dma_descriptor_num)/1024;
                                         curr.run_write = bk_ptr->dma_status.run_write;
                                         curr.run_read = bk_ptr->dma_status.run_read;
                                         curr.run_simul = bk_ptr->dma_status.run_simul;
                                         curr.length_transfer = bk_ptr->dma_status.length_transfer;
                                         curr.write_time = bk_ptr->dma_status.write_time;
                                         curr.read_time = bk_ptr->dma_status.read_time;
                                         curr.simul_time = bk_ptr->dma_status.simul_time;
                                         curr.pass_read = bk_ptr->dma_status.pass_read;
                                         curr.pass_write = bk_ptr->dma_status.pass_write;
                                         curr.pass_simul = bk_ptr->dma_status.pass_simul;
                                         curr.altera_dma_num_dwords = bk_ptr->dma_status.altera_dma_num_dwords;
                                         curr.altera_dma_descriptor_num = bk_ptr->dma_status.altera_dma_descriptor_num;
                                         curr.offset = bk_ptr->dma_status.offset;
                                         curr.read_eplast_timeout = bk_ptr->dma_status.read_eplast_timeout;
                                         curr.write_eplast_timeout = bk_ptr->dma_status.write_eplast_timeout;
                                         if (copy_to_user (kcmd.buf, &curr, sizeof(struct dma_status))) {
                                             rc = -EFAULT;
                                             return rc;
                                         }
                                         break;            
                                     }
        default:
                                     printk(KERN_DEBUG "command issued from user space doesn't exist %d", kcmd.cmd);
    }
    return 0;
}

int altera_dma_open(struct inode *inode, struct file *file) {
    struct altera_pcie_dma_bookkeep *bk_ptr = 0;

    bk_ptr = container_of(inode->i_cdev, struct altera_pcie_dma_bookkeep, cdev);
    file->private_data = bk_ptr;
    bk_ptr->user_pid = current->pid;

    return 0;
}

int altera_dma_release(struct inode *inode, struct file *file) {
    return 0;
}

static irqreturn_t dma_isr(int irq, void *dev_id)
{
    printk("Test, received ISR\n");
    return IRQ_HANDLED;
}

struct file_operations altera_dma_fops = {
    .owner          = THIS_MODULE,
    .read           = altera_dma_read,
    .write          = (void *)altera_dma_write,
    .open           = altera_dma_open,
    .release        = altera_dma_release,
    .unlocked_ioctl = altera_dma_ioctl,
};

static int __init init_chrdev (struct altera_pcie_dma_bookkeep *bk_ptr) {
    int dev_minor = 0;
    int dev_major = 0;
    int devno = -1;

    int result = alloc_chrdev_region(&bk_ptr->cdevno, dev_minor, 1, ALTERA_DMA_DEVFILE);

    dev_major = MAJOR(bk_ptr->cdevno);
    if (result < 0) {
        printk(KERN_DEBUG "cannot get major ID %d", dev_major);
    }

    devno = MKDEV(dev_major, dev_minor);

    cdev_init(&bk_ptr->cdev, &altera_dma_fops);
    bk_ptr->cdev.owner = THIS_MODULE;
    bk_ptr->cdev.ops = &altera_dma_fops;
    result = cdev_add(&bk_ptr->cdev, devno, 1);

    if (result)
        return -1; 
    return 0;
}
/*
static int set_table_header(struct dma_header *header, u32 eplast)
{
    header->eplast = cpu_to_le32(eplast);
    header->reserved[0] = cpu_to_le32(0x0);    
    header->reserved[1] = cpu_to_le32(0x0);    
    header->reserved[2] = cpu_to_le32(0x0);    
    header->reserved[3] = cpu_to_le32(0x0);    
    return 0;
}

static int print_table_header(struct dma_header *header)
{
    printk(KERN_DEBUG "Print Header:"                  );  
    printk(KERN_DEBUG "0x%x\n",    *(u32*)header       );  
    printk(KERN_DEBUG "0x%x\n",    *((u32*)header+0x1) ); 
    printk(KERN_DEBUG "0x%x\n",    *((u32*)header+0x2) );
    printk(KERN_DEBUG "0x%x\n",    *((u32*)header+0x3) );
    printk(KERN_DEBUG "0x%x\n",    *((u32*)header+0x4) );
    return 0;
}
*/
static int set_read_desc(struct dma_descriptor *rd_desc, dma_addr_t source, u64 dest, u32 ctl_dma_len, u32 id)
{
    rd_desc->src_addr_ldw = cpu_to_le32(source & 0xffffffffUL);
    rd_desc->src_addr_udw = cpu_to_le32((source >> 32));
    rd_desc->dest_addr_ldw = cpu_to_le32(dest & 0xffffffffUL);
    rd_desc->dest_addr_udw = cpu_to_le32((dest >> 32));
    rd_desc->ctl_dma_len = cpu_to_le32(ctl_dma_len | (id << 18));
    rd_desc->reserved[0] = cpu_to_le32(0x0);
    rd_desc->reserved[1] = cpu_to_le32(0x0);
    rd_desc->reserved[2] = cpu_to_le32(0x0);
    return 0;
}

/*
   static int print_desc(struct dma_descriptor *desc)
   {

   printk(KERN_DEBUG "Print Desc"                   );  
   printk(KERN_DEBUG "0x%x\n",    *(u32*)desc       );  
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x1) ); 
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x2) );
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x3) );
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x4) );
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x5) );
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x6) );
   printk(KERN_DEBUG "0x%x\n",    *((u32*)desc+0x7) );
   return 0;
   }*/

static int set_write_desc(struct dma_descriptor *wr_desc, u64 source, dma_addr_t dest, u32 ctl_dma_len, u32 id)
{
    wr_desc->src_addr_ldw = cpu_to_le32(source & 0xffffffffUL);
    wr_desc->src_addr_udw = cpu_to_le32((source >> 32));
    wr_desc->dest_addr_ldw = cpu_to_le32(dest & 0xffffffffUL);
    wr_desc->dest_addr_udw = cpu_to_le32((dest >> 32));
    wr_desc->ctl_dma_len = cpu_to_le32(ctl_dma_len | (id << 18));
    wr_desc->reserved[0] = cpu_to_le32(0x0);
    wr_desc->reserved[1] = cpu_to_le32(0x0);
    wr_desc->reserved[2] = cpu_to_le32(0x0);
    return 0;
}

static int scan_bars(struct altera_pcie_dma_bookkeep *bk_ptr, struct pci_dev *dev)
{
    int i;
    for (i = 0; i < ALTERA_DMA_BAR_NUM; i++) {
        unsigned long bar_start = pci_resource_start(dev, i);
        unsigned long bar_end = pci_resource_end(dev, i);
        unsigned long bar_flags = pci_resource_flags(dev, i);
        bk_ptr->bar_length[i] = pci_resource_len(dev, i);
        dev_info(&dev->dev, "BAR[%d] 0x%08lx-0x%08lx flags 0x%08lx, length %d", i, bar_start, bar_end, bar_flags, (int)bk_ptr->bar_length[i]);
    }
    return 0; 
}

static int init_rp_mem(u8 *rp_buffer_virt_addr, u32 num_dwords, u32 init_value, u8 increment)
{
    u32 i = 0;
    u32 increment_value = 0;
    u32 tmp_rand;
    for (i = 0; i < num_dwords; i++) {    
//	if (increment)   increment_value = i;  
//        *((u32*)rp_buffer_virt_addr+increment_value) = cpu_to_le32(init_value+increment_value);
	get_random_bytes(&tmp_rand, sizeof(tmp_rand));
        *((u32*)rp_buffer_virt_addr+increment_value) = cpu_to_le32(tmp_rand);
    }
    //printk(KERN_DEBUG "random data = %08x", tmp_rand);
    return 0;
}

static int rp_compare(u8 *virt_addr1, u8 *virt_addr2, u32 num_dwords)
{
    u32 i = 0;
    //printk(KERN_DEBUG "ORIGINAL                FINAL");
    for (i = 0; i < num_dwords; i++) {  
        if ( *((u32*)virt_addr1+i) != *((u32*)virt_addr2+i)) {
            printk(KERN_DEBUG "%p: 0x%08x != %p: 0x%08x => Data mismatch", (u64 *)((u32*)virt_addr1+i),*((u32*)virt_addr1+i), (u64 *)((u32*)virt_addr2+i),*((u32*)virt_addr2+i));
            return -1;
        } else {
            //printk(KERN_DEBUG "%p: 0x%08x == %p: 0x%08x", (u64 *)((u32*)virt_addr1+i),*((u32*)virt_addr1+i), (u64 *)((u32*)virt_addr2+i),*((u32*)virt_addr2+i));
        }
    }
    return 0;
}

static int rp_ep_compare(u8 *virt_addr, struct altera_pcie_dma_bookkeep *bk_ptr, u32 mem_byte_offset, u32 num_dwords)
{
    u32 i = 0;
    u32 rp_data = 0;
    u32 ep_data = 0;
    //printk(KERN_DEBUG "RP                      EP");
    for (i = 0; i < num_dwords; i++) {
        ep_data = ioread32((u32 *)(bk_ptr->bar[4]+mem_byte_offset+ONCHIP_MEM_BASE)+i);
        rmb();
        rp_data = *((u32*)virt_addr+i); 
        if ( ep_data != rp_data ) {
            printk(KERN_DEBUG "%p: 0x%08x != %p: 0x%08x => Data mismatch", (u64 *)((u32*)virt_addr+i), rp_data, (u32 *)(bk_ptr->bar[4]+mem_byte_offset+ONCHIP_MEM_BASE)+i, ep_data); 
            return -1;
        } else {
            //printk(KERN_DEBUG "%p: 0x%08x == %p: 0x%08x", (u64 *)((u32*)virt_addr+i), rp_data, (u32 *)(bk_ptr->bar[0]+mem_byte_offset+ONCHIP_MEM_BASE)+i, ep_data); 
        }
    }
    return 0;
}
/*
   static int print_ep_data(struct altera_pcie_dma_bookkeep *bk_ptr, u32 mem_byte_offset, u32 num_dwords)
   {
   u32 i = 0;
   u32 ep_data = 0;
   printk(KERN_DEBUG "Printing EP data");
   for (i = 0; i < num_dwords; i++) {
   ep_data = ioread32((u32 *)(bk_ptr->bar[0]+mem_byte_offset+ONCHIP_MEM_BASE)+i);
   rmb();
   printk(KERN_DEBUG "%p: 0x%08x", (u32 *)(bk_ptr->bar[0]+mem_byte_offset+ONCHIP_MEM_BASE)+i, ep_data); 
   }
   return 0;
   }
 */

/*
   static int print_rp_data(u8 *virt_addr, u32 num_dwords)
   {
   u32 i = 0;
   for (i = 0; i < num_dwords; i++) { 
   printk(KERN_DEBUG "%p: 0x%08x", (u64 *)((u32*)virt_addr+i),*((u32*)virt_addr+i));
   }
   return 0;
   }
 */

static int init_ep_mem(struct altera_pcie_dma_bookkeep *bk_ptr, u32 mem_byte_offset, u32 num_dwords, u32 init_value, u8 increment)
{
    u32 i = 0;
    u32 increment_value = 0;
    u32 tmp_rand;
    for (i = 0; i < num_dwords; i++) {
        if (increment) increment_value = i;  
//        iowrite32 (cpu_to_le32(init_value+increment_value), (u32 *)(bk_ptr->bar[0]+mem_byte_offset)+increment_value);
	get_random_bytes(&tmp_rand, sizeof(tmp_rand));
        iowrite32 (cpu_to_le32(tmp_rand), (u32 *)(bk_ptr->bar[4]+mem_byte_offset)+increment_value);
        wmb();
    }
    return 0;
}

static int set_lite_table_header(struct lite_dma_header *header)
{
    int i;
    for (i = 0; i < 128; i++)
        header->flags[i] = cpu_to_le32(0x0); 
    return 0;
}

static int dma_test(struct altera_pcie_dma_bookkeep *bk_ptr, struct pci_dev *dev)
{

    u8 *rp_rd_buffer_virt_addr = bk_ptr->rp_rd_buffer_virt_addr;
    dma_addr_t rp_rd_buffer_bus_addr = bk_ptr->rp_rd_buffer_bus_addr;
    u8 *rp_wr_buffer_virt_addr = bk_ptr->rp_wr_buffer_virt_addr;
    dma_addr_t rp_wr_buffer_bus_addr = bk_ptr->rp_wr_buffer_bus_addr;
    int loop_count = 0, num_loop_count = 2, simul_read_count, simul_write_count;
    int i, j;
    struct timeval tv1;
    struct timeval tv2;
    struct timeval diff;
    atomic_set(&bk_ptr->status, 1);
    bk_ptr->dma_status.pass_read = 0;     
    bk_ptr->dma_status.pass_write = 0;     
    bk_ptr->dma_status.pass_simul = 0;     
    memset(rp_rd_buffer_virt_addr, 0, bk_ptr->dma_status.altera_dma_num_dwords*4);
    memset(rp_wr_buffer_virt_addr, 0, bk_ptr->dma_status.altera_dma_num_dwords*4);
    init_rp_mem(rp_rd_buffer_virt_addr, bk_ptr->dma_status.altera_dma_num_dwords, 0x00000000, 1);

//    init_ep_mem(bk_ptr, bk_ptr->dma_status.altera_dma_num_dwords*4, bk_ptr->dma_status.altera_dma_num_dwords, 0x0, 1);
    if(bk_ptr->dma_status.run_read) {
        set_lite_table_header((struct lite_dma_header *)bk_ptr->lite_table_rd_cpu_virt_addr);
        wmb();
        for (i = 0; i < bk_ptr->dma_status.altera_dma_descriptor_num; i++) {
            set_read_desc(&bk_ptr->lite_table_rd_cpu_virt_addr->descriptors[i], (dma_addr_t)rp_rd_buffer_bus_addr, (u64)ONCHIP_MEM_BASE, bk_ptr->dma_status.altera_dma_num_dwords, i);
        }
        iowrite32 ((dma_addr_t)bk_ptr->lite_table_rd_bus_addr, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_RC_LOW_SRC_ADDR);
        iowrite32 (((dma_addr_t)bk_ptr->lite_table_rd_bus_addr)>>32, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_RC_HIGH_SRC_ADDR);
        iowrite32 (0x01000000, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_CTLR_LOW_DEST_ADDR);
        iowrite32 (0x0, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_CTRL_HIGH_DEST_ADDR);

        wmb();

        for (i = ALTERA_EPLAST_DIFF-1; i <= 127; i = i + ALTERA_EPLAST_DIFF) { 
            iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_LAST_PTR);
            wmb();
        }

        if (i > 127 && ((i-ALTERA_EPLAST_DIFF) != 127)) {
            iowrite32 (127, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_LAST_PTR);
            wmb();
        }

        do_gettimeofday(&tv1);  
        for (loop_count = 0; loop_count < num_loop_count; loop_count++) { 
            for (i = ALTERA_EPLAST_DIFF-1; i < 127 + ALTERA_EPLAST_DIFF; i = i + ALTERA_EPLAST_DIFF) {
                if (i > 127)
                    i = 127;
                while (1) {
                    if (bk_ptr->lite_table_rd_cpu_virt_addr->header.flags[i]) {
                        bk_ptr->lite_table_rd_cpu_virt_addr->header.flags[i] = 0;
                        if (!(loop_count == num_loop_count-1))
                            iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_LAST_PTR);
                        break;
                    }
                    cpu_relax();
                }
            }
        }
        do_gettimeofday(&tv2);  
        diff_timeval(&diff, &tv2, &tv1);
        bk_ptr->dma_status.read_time = diff; 

        //if (0) { //rp_ep_compare(rp_rd_buffer_virt_addr, bk_ptr, 0, bk_ptr->dma_status.altera_dma_num_dwords)) {
	if (rp_ep_compare(rp_rd_buffer_virt_addr, bk_ptr, 0, bk_ptr->dma_status.altera_dma_num_dwords)) {
            bk_ptr->dma_status.pass_read = 0;

        }
        else
            bk_ptr->dma_status.pass_read = 1;

    }

    if (bk_ptr->dma_status.run_write) {
        memset(rp_wr_buffer_virt_addr, 0, bk_ptr->dma_status.altera_dma_num_dwords*4);
        set_lite_table_header((struct lite_dma_header *)bk_ptr->lite_table_wr_cpu_virt_addr);
        wmb();
        for (i = 0; i < bk_ptr->dma_status.altera_dma_descriptor_num; i++) {
            set_write_desc(&bk_ptr->lite_table_wr_cpu_virt_addr->descriptors[i], ONCHIP_MEM_BASE, (dma_addr_t)rp_wr_buffer_bus_addr, bk_ptr->dma_status.altera_dma_num_dwords, i);
        }

        iowrite32 ((dma_addr_t)bk_ptr->lite_table_wr_bus_addr, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_RC_LOW_SRC_ADDR);
        iowrite32 (((dma_addr_t)bk_ptr->lite_table_wr_bus_addr)>>32, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_RC_HIGH_SRC_ADDR);
        iowrite32 (0x01002000, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_CTLR_LOW_DEST_ADDR);
        iowrite32 (0x0, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_CTRL_HIGH_DEST_ADDR);

        wmb();
        do_gettimeofday(&tv1);  
        for (i = ALTERA_EPLAST_DIFF - 1; i <= 127; i = i + ALTERA_EPLAST_DIFF) 
            iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_LAST_PTR);

        if (i > 127 && ((i-ALTERA_EPLAST_DIFF) != 127)) {
            iowrite32 (127, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_LAST_PTR);
            wmb();
        }

        for (loop_count = 0; loop_count < num_loop_count; loop_count++) { 
            for (i = ALTERA_EPLAST_DIFF - 1; i < 127 + ALTERA_EPLAST_DIFF; i = i + ALTERA_EPLAST_DIFF) {
                if (i > 127)
                    i = 127;
                while (1) {
                    if (bk_ptr->lite_table_wr_cpu_virt_addr->header.flags[i]) {
                        bk_ptr->lite_table_wr_cpu_virt_addr->header.flags[i] = 0;
                        if (!(loop_count == num_loop_count-1))
                            iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_LAST_PTR);
                        break;
                    }
                    cpu_relax();
                }
            }
        }
        do_gettimeofday(&tv2);  
        diff_timeval(&diff, &tv2, &tv1);
        bk_ptr->dma_status.write_time = diff;

        //if (rp_compare(rp_rd_buffer_virt_addr, rp_wr_buffer_virt_addr, bk_ptr->dma_status.altera_dma_num_dwords)) {
	if (rp_ep_compare(rp_wr_buffer_virt_addr, bk_ptr, 0, bk_ptr->dma_status.altera_dma_num_dwords)) {
            bk_ptr->dma_status.pass_write = 0;     
        }
        else
            bk_ptr->dma_status.pass_write = 1;    
    }

    if(bk_ptr->dma_status.run_simul) {
        set_lite_table_header((struct lite_dma_header *)bk_ptr->lite_table_rd_cpu_virt_addr);
        set_lite_table_header((struct lite_dma_header *)bk_ptr->lite_table_wr_cpu_virt_addr);
        memset(rp_rd_buffer_virt_addr, 0, bk_ptr->dma_status.altera_dma_num_dwords*4);
        memset(rp_wr_buffer_virt_addr, 0, bk_ptr->dma_status.altera_dma_num_dwords*4);
        init_rp_mem(rp_rd_buffer_virt_addr, bk_ptr->dma_status.altera_dma_num_dwords, 0x00000000, 1);
        init_ep_mem(bk_ptr, bk_ptr->dma_status.altera_dma_num_dwords*4, bk_ptr->dma_status.altera_dma_num_dwords, 0x0, 1);
        wmb();

        for (i = 0; i < bk_ptr->dma_status.altera_dma_descriptor_num; i++) {
            set_read_desc(&bk_ptr->lite_table_rd_cpu_virt_addr->descriptors[i], (dma_addr_t)rp_rd_buffer_bus_addr, ONCHIP_MEM_BASE, bk_ptr->dma_status.altera_dma_num_dwords, i);
        }
        for (i = 0; i < bk_ptr->dma_status.altera_dma_descriptor_num; i++) {
            set_write_desc(&bk_ptr->lite_table_wr_cpu_virt_addr->descriptors[i], ONCHIP_MEM_BASE+4*bk_ptr->dma_status.altera_dma_num_dwords, (dma_addr_t)(rp_wr_buffer_bus_addr), bk_ptr->dma_status.altera_dma_num_dwords, i);
        }

        iowrite32 ((dma_addr_t)bk_ptr->lite_table_rd_bus_addr, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_RC_LOW_SRC_ADDR);
        iowrite32 (((dma_addr_t)bk_ptr->lite_table_rd_bus_addr)>>32, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_RC_HIGH_SRC_ADDR);
        iowrite32 (0x01000000, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_CTLR_LOW_DEST_ADDR);
        iowrite32 (0x0, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_CTRL_HIGH_DEST_ADDR);

        iowrite32 ((dma_addr_t)bk_ptr->lite_table_wr_bus_addr, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_RC_LOW_SRC_ADDR);
        iowrite32 (((dma_addr_t)bk_ptr->lite_table_wr_bus_addr)>>32, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_RC_HIGH_SRC_ADDR);
        iowrite32 (0x01002000, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_CTLR_LOW_DEST_ADDR);
        iowrite32 (0x0, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_CTRL_HIGH_DEST_ADDR);
        wmb();

        do_gettimeofday(&tv1);  
        for (i = ALTERA_EPLAST_DIFF - 1; i <= 127; i = i + ALTERA_EPLAST_DIFF) 
            iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_LAST_PTR);

        if (i > 127 && ((i-ALTERA_EPLAST_DIFF) != 127)) {
            iowrite32 (127, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_LAST_PTR);
            wmb();
        }

        for (i = ALTERA_EPLAST_DIFF - 1; i <= 127; i = i + ALTERA_EPLAST_DIFF) 
            iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_LAST_PTR);

        if (i > 127 && ((i-ALTERA_EPLAST_DIFF) != 127)) {
            iowrite32 (127, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_LAST_PTR);
            wmb();
        }

        i = ALTERA_EPLAST_DIFF-1;
        j = ALTERA_EPLAST_DIFF-1;
 
        simul_read_count = 0;
        simul_write_count = 0;
        while (1) {
            if (bk_ptr->lite_table_rd_cpu_virt_addr->header.flags[i] && simul_read_count < num_loop_count) {
                bk_ptr->lite_table_rd_cpu_virt_addr->header.flags[i] = 0;
                //printk("found read: %d", i);
                if (!(simul_read_count == num_loop_count-1)) {
                    iowrite32 (i, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_RD_LAST_PTR);
                    //printk("sent read: %d", i);
                }
                if (i == 127) {
                    simul_read_count++;
                    //printk(" read loop: ");
                    i = ALTERA_EPLAST_DIFF-1;
                } else {
                    i = i + ALTERA_EPLAST_DIFF;
                    if (i > 127)
                        i = 127;
                }
            }
            
            if (bk_ptr->lite_table_wr_cpu_virt_addr->header.flags[j] && simul_write_count < num_loop_count) {
                bk_ptr->lite_table_wr_cpu_virt_addr->header.flags[j] = 0;
                //printk("found write: %d", j);
                if (!(simul_write_count == num_loop_count-1)) {
                    iowrite32 (j, bk_ptr->bar[0]+DESC_CTRLLER_BASE+ALTERA_LITE_DMA_WR_LAST_PTR);
                    //printk("sent write: %d", j);
                }
                if (j == 127) {
                    simul_write_count++;
                    //printk(" write loop: ");
                    j = ALTERA_EPLAST_DIFF-1;
                } else {
                    j = j + ALTERA_EPLAST_DIFF;
                    if (j > 127)
                        j = 127;
                }
            }
            if ((simul_read_count == num_loop_count && simul_write_count == num_loop_count))
                break;
            cpu_relax();
        }

        do_gettimeofday(&tv2);  
        diff_timeval(&diff, &tv2, &tv1);
        bk_ptr->dma_status.simul_time = diff;

       if (rp_ep_compare((u8 *)rp_rd_buffer_virt_addr, bk_ptr, 0, bk_ptr->dma_status.altera_dma_num_dwords) || rp_ep_compare((u8 *)rp_wr_buffer_virt_addr, bk_ptr, bk_ptr->dma_status.altera_dma_num_dwords*4, bk_ptr->dma_status.altera_dma_num_dwords)) {
            bk_ptr->dma_status.pass_simul = 0;
        }     
        else
          bk_ptr->dma_status.pass_simul = 1;
    }

    atomic_set(&bk_ptr->status, 0);
    wake_up(&bk_ptr->wait_q);
    return 0;

}

static int __init map_bars(struct altera_pcie_dma_bookkeep *bk_ptr, struct pci_dev *dev)
{
    int i;
    for (i = 0; i < ALTERA_DMA_BAR_NUM; i++) {
        unsigned long bar_start = pci_resource_start(dev, i);
        //unsigned long bar_end = pci_resource_end(dev, i);
        //unsigned long bar_flags = pci_resource_flags(dev, i);
        bk_ptr->bar_length[i] = pci_resource_len(dev, i);
        if (!bk_ptr->bar_length[i]) {
            bk_ptr->bar[i] = NULL;
            continue;
        }
        bk_ptr->bar[i] = ioremap(bar_start, bk_ptr->bar_length[i]);
        if (!bk_ptr->bar[i]) {
            dev_err(&dev->dev, "could not map BAR[%d]", i);
            return -1;
        } else
            dev_info(&dev->dev, "BAR[%d] mapped to 0x%p, length %lu", i, bk_ptr->bar[i], (long unsigned int)bk_ptr->bar_length[i]); 
    }
    return 0;
}

static void unmap_bars(struct altera_pcie_dma_bookkeep *bk_ptr, struct pci_dev *dev)
{
    int i;
    for (i = 0; i < ALTERA_DMA_BAR_NUM; i++) {
        if (bk_ptr->bar[i]) {
            pci_iounmap(dev, bk_ptr->bar[i]);
            bk_ptr->bar[i] = NULL;
        }
    }
}
static int __init altera_pci_probe(struct pci_dev *dev, const struct pci_device_id *id)
{
    int rc = 0;
    struct altera_pcie_dma_bookkeep *bk_ptr = NULL;

    bk_ptr = kzalloc(sizeof(struct altera_pcie_dma_bookkeep), GFP_KERNEL);
    if(!bk_ptr)
        goto err_bk_alloc;

    bk_ptr->pci_dev = dev;
    pci_set_drvdata(dev, bk_ptr);

    rc = init_chrdev(bk_ptr); 
    if (rc) {
        dev_err(&dev->dev, "init_chrdev() failed\n");
        goto err_initchrdev;
    }
    rc = pci_enable_device(dev);
    if (rc) {
        dev_err(&dev->dev, "pci_enable_device() failed\n");
        goto err_enable;
    } else {
        dev_info(&dev->dev, "pci_enable_device() successful");
    }
    rc = pci_request_regions(dev, ALTERA_DMA_DRIVER_NAME);
    if (rc) {
        dev_err(&dev->dev, "pci_request_regions() failed\n");
        goto err_regions;
    }
    pci_set_master(dev);
    rc = pci_enable_msi(dev);
    if (rc) {
        dev_info(&dev->dev, "pci_enable_msi() failed\n");
        bk_ptr->msi_enabled = 0;
    } else {
        dev_info(&dev->dev, "pci_enable_msi() successful\n");
        bk_ptr->msi_enabled = 1;
    }
    pci_read_config_byte(dev, PCI_REVISION_ID, &bk_ptr->revision);
    pci_read_config_byte(dev, PCI_INTERRUPT_PIN, &bk_ptr->irq_pin);
    pci_read_config_byte(dev, PCI_INTERRUPT_LINE, &bk_ptr->irq_line);

    if (!pci_set_dma_mask(dev, DMA_BIT_MASK(64))) {
        pci_set_consistent_dma_mask(dev, DMA_BIT_MASK(64));
        dev_info(&dev->dev, "using a 64-bit irq mask\n");
    } else {
        dev_info(&dev->dev, "unable to use 64-bit irq mask\n");
        goto err_dma_mask;
    }

    dev_info(&dev->dev, "irq pin: %d\n", bk_ptr->irq_pin);
    dev_info(&dev->dev, "irq line: %d\n", bk_ptr->irq_line);
    dev_info(&dev->dev, "irq: %d\n", dev->irq);

    rc = 0;
    
    request_irq(bk_ptr->irq_line, dma_isr, IRQF_SHARED, ALTERA_DMA_DRIVER_NAME, (void *)bk_ptr); 
    if (rc) {
        dev_info(&dev->dev, "Could not request IRQ #%d", bk_ptr->irq_line);
        bk_ptr->irq_line = -1;
        goto err_irq;
    } else {
        dev_info(&dev->dev, "request irq: %d", bk_ptr->irq_line);
    }

    scan_bars(bk_ptr, dev);
    map_bars(bk_ptr, dev);

    // waitqueue for user process
    init_waitqueue_head(&bk_ptr->wait_q);

    // set default settings to run
    bk_ptr->dma_status.altera_dma_num_dwords = ALTERA_DMA_NUM_DWORDS;
    bk_ptr->dma_status.altera_dma_descriptor_num = ALTERA_DMA_DESCRIPTOR_NUM;
    bk_ptr->dma_status.run_write = 1;
    bk_ptr->dma_status.run_read = 1;
    bk_ptr->dma_status.run_simul = 1;
    bk_ptr->dma_status.offset = 0;
    bk_ptr->table_rd_cpu_virt_addr = ((struct dma_desc_table *)pci_alloc_consistent(dev, sizeof(struct dma_desc_table), &bk_ptr->table_rd_bus_addr));
    bk_ptr->lite_table_rd_cpu_virt_addr = ((struct lite_dma_desc_table *)pci_alloc_consistent(dev, sizeof(struct lite_dma_desc_table), &bk_ptr->lite_table_rd_bus_addr));
    if (!bk_ptr->table_rd_cpu_virt_addr || !bk_ptr->lite_table_rd_cpu_virt_addr) {
        rc = -ENOMEM;
        goto err_rd_table;
    }
    bk_ptr->table_wr_cpu_virt_addr = ((struct dma_desc_table *)pci_alloc_consistent(dev, sizeof(struct dma_desc_table), &bk_ptr->table_wr_bus_addr));
    bk_ptr->lite_table_wr_cpu_virt_addr = ((struct lite_dma_desc_table *)pci_alloc_consistent(dev, sizeof(struct lite_dma_desc_table), &bk_ptr->lite_table_wr_bus_addr));
    if (!bk_ptr->table_wr_cpu_virt_addr || !bk_ptr->lite_table_wr_cpu_virt_addr) {
        rc = -ENOMEM;
        goto err_wr_table;
    }
    bk_ptr->numpages = (PAGE_SIZE >= MAX_NUM_DWORDS*4) ? 1 : (int)((MAX_NUM_DWORDS*4)/PAGE_SIZE);
    bk_ptr->rp_rd_buffer_virt_addr = pci_alloc_consistent(dev, PAGE_SIZE*bk_ptr->numpages, &bk_ptr->rp_rd_buffer_bus_addr);
    if (!bk_ptr->rp_rd_buffer_virt_addr) {
        rc = -ENOMEM;
        goto err_rd_buffer;
    }
    bk_ptr->rp_wr_buffer_virt_addr = pci_alloc_consistent(dev, PAGE_SIZE*bk_ptr->numpages, &bk_ptr->rp_wr_buffer_bus_addr);
    if (!bk_ptr->rp_wr_buffer_virt_addr) {
        rc = -ENOMEM;
        goto err_wr_buffer;
    }
    return 0;

    // error clean up
err_wr_buffer:
    dev_err(&dev->dev, "goto err_wr_buffer");
    pci_free_consistent(dev, PAGE_SIZE*bk_ptr->numpages, bk_ptr->rp_rd_buffer_virt_addr, bk_ptr->rp_rd_buffer_bus_addr);
err_rd_buffer:
    dev_err(&dev->dev, "goto err_rd_buffer");
    pci_free_consistent(dev, sizeof(struct dma_desc_table), bk_ptr->table_wr_cpu_virt_addr, bk_ptr->table_wr_bus_addr);
err_wr_table:
    dev_err(&dev->dev, "goto err_wr_table");
    pci_free_consistent(dev, sizeof(struct dma_desc_table), bk_ptr->table_rd_cpu_virt_addr, bk_ptr->table_rd_bus_addr);
err_rd_table:
    dev_err(&dev->dev, "goto err_rd_table");
err_irq:
    dev_err(&dev->dev, "goto err_regions");
err_dma_mask:
    dev_err(&dev->dev, "goto err_dma_mask");
    pci_release_regions(dev);
err_regions:
    dev_err(&dev->dev, "goto err_irq");
    pci_disable_device(dev);
err_enable:
    dev_err(&dev->dev, "goto err_enable");
    unregister_chrdev_region (bk_ptr->cdevno, 1);
err_initchrdev:
    dev_err(&dev->dev, "goto err_initchrdev");
    kfree(bk_ptr);
err_bk_alloc:
    dev_err(&dev->dev, "goto err_bk_alloc");
    return rc;
}


static void __exit altera_pci_remove(struct pci_dev *dev)
{
    struct altera_pcie_dma_bookkeep *bk_ptr = NULL;
    bk_ptr = pci_get_drvdata(dev);
    cdev_del(&bk_ptr->cdev);
    unregister_chrdev_region(bk_ptr->cdevno, 1);
    pci_disable_device(dev);
    if(bk_ptr) {
        if(bk_ptr->msi_enabled) {
            pci_disable_msi(dev);
            bk_ptr->msi_enabled = 0;
        }
    }
    unmap_bars(bk_ptr, dev);
    pci_release_regions(dev);
    if (bk_ptr->irq_line >= 0) {
        printk(KERN_DEBUG "Freeing IRQ #%d", bk_ptr->irq_line);
        free_irq(bk_ptr->irq_line, (void *)bk_ptr);
    }
    pci_free_consistent(dev, sizeof(struct dma_desc_table), bk_ptr->table_rd_cpu_virt_addr, bk_ptr->table_rd_bus_addr);
    pci_free_consistent(dev, sizeof(struct lite_dma_desc_table), bk_ptr->lite_table_rd_cpu_virt_addr, bk_ptr->lite_table_rd_bus_addr);
    pci_free_consistent(dev, sizeof(struct dma_desc_table), bk_ptr->table_wr_cpu_virt_addr, bk_ptr->table_wr_bus_addr);
    pci_free_consistent(dev, sizeof(struct lite_dma_desc_table), bk_ptr->lite_table_wr_cpu_virt_addr, bk_ptr->lite_table_wr_bus_addr);
    pci_free_consistent(dev, PAGE_SIZE*bk_ptr->numpages, bk_ptr->rp_rd_buffer_virt_addr, bk_ptr->rp_rd_buffer_bus_addr);
    pci_free_consistent(dev, PAGE_SIZE*bk_ptr->numpages, bk_ptr->rp_wr_buffer_virt_addr, bk_ptr->rp_wr_buffer_bus_addr);

    kfree(bk_ptr);
    printk(KERN_DEBUG ALTERA_DMA_DRIVER_NAME ": " "altera_dma_remove()," " " __DATE__ " " __TIME__ " " "\n");
}

static struct pci_device_id pci_ids[] = {
    { PCI_DEVICE(ALTERA_DMA_VID, ALTERA_DMA_DID) },
    { 0 }
};

static struct pci_driver dma_driver_ops = {
    .name = ALTERA_DMA_DRIVER_NAME,
    .id_table = pci_ids,
    .probe = altera_pci_probe,
    .remove = altera_pci_remove,
};

static int __init altera_dma_init(void)
{
    int rc = 0;

    printk(KERN_DEBUG ALTERA_DMA_DRIVER_NAME ": " "altera_dma_init()," " " __DATE__ " " __TIME__ " " "\n");
    rc = pci_register_driver(&dma_driver_ops);
    if (rc) {
        printk(KERN_ERR ALTERA_DMA_DRIVER_NAME ": PCI driver registration failed\n");
        goto exit;
    }

exit:
    return rc;
}

static void __exit altera_dma_exit(void)
{
    pci_unregister_driver(&dma_driver_ops);
}
/*
static int eplast_busy_wait(struct altera_pcie_dma_bookkeep *bk_ptr, u32 expected_eplast, u8 rw)
{
    // rw: 1 = read, 0 = write
    u32 timeout = 0;
    u32 eplast = 0;
    while (1) {
        eplast = (rw == 1? *(u32*)bk_ptr->table_rd_cpu_virt_addr: *(u32*)bk_ptr->table_wr_cpu_virt_addr);
        if (eplast == expected_eplast)
            break; 
        ++timeout;
        if (timeout == TIMEOUT_THRESH) {
            printk(KERN_DEBUG "Timed out waiting for EPLAST");
            if (rw == 1)
                bk_ptr->dma_status.read_eplast_timeout = 1;
            else
                bk_ptr->dma_status.write_eplast_timeout = 1;
            return -1;
        }
        udelay(1);
    }
    if (rw == 1)
        bk_ptr->dma_status.read_eplast_timeout = 0;
    else
        bk_ptr->dma_status.write_eplast_timeout = 0;
    return 0;
}
*/
static int diff_timeval(struct timeval *result, struct timeval *t2, struct timeval *t1)
{
    long int diff = (t2->tv_usec + 1000000 * t2->tv_sec) - (t1->tv_usec + 1000000 * t1->tv_sec);
    result->tv_sec = diff / 1000000;
    result->tv_usec = diff % 1000000;
    return ( diff < 0 );
}

module_init(altera_dma_init);
module_exit(altera_dma_exit);

MODULE_AUTHOR("Michael Chen <micchen@altera.com>");
MODULE_DESCRIPTION("256b DMA Driver");
MODULE_VERSION(ALTERA_DMA_DRIVER_VERSION);
MODULE_LICENSE("Dual BSD/GPL");
MODULE_DEVICE_TABLE(pci, pci_ids);


